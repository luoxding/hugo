<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Dialects on MLIR</title><link>https://mlir.llvm.org/docs/Dialects/</link><description>Recent content in Dialects on MLIR</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 01 Jan 1970 00:00:00 +0000</lastBuildDate><atom:link href="https://mlir.llvm.org/docs/Dialects/index.xml" rel="self" type="application/rss+xml"/><item><title>'acc' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/OpenACCDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/OpenACCDialect/</guid><description>An OpenACC dialect for MLIR. This dialect models the construct from the OpenACC 3.3 directive language.
Operations acc.atomic.capture (acc::AtomicCaptureOp) acc.atomic.read (acc::AtomicReadOp) acc.atomic.update (acc::AtomicUpdateOp) acc.atomic.write (acc::AtomicWriteOp) acc.attach (acc::AttachOp) acc.bounds (acc::DataBoundsOp) acc.cache (acc::CacheOp) acc.copyin (acc::CopyinOp) acc.copyout (acc::CopyoutOp) acc.create (acc::CreateOp) acc.data (acc::DataOp) acc.declare (acc::DeclareOp) acc.declare_device_resident (acc::DeclareDeviceResidentOp) acc.declare_enter (acc::DeclareEnterOp) acc.declare_exit (acc::DeclareExitOp) acc.declare_link (acc::DeclareLinkOp) acc.delete (acc::DeleteOp) acc.detach (acc::DetachOp) acc.deviceptr (acc::DevicePtrOp) acc.enter_data (acc::EnterDataOp) acc.exit_data (acc::ExitDataOp) acc.firstprivate (acc::FirstprivateOp) acc.firstprivate.recipe (acc::FirstprivateRecipeOp) acc.getdeviceptr (acc::GetDevicePtrOp) acc.global_ctor (acc::GlobalConstructorOp) acc.global_dtor (acc::GlobalDestructorOp) acc.</description></item><item><title>'affine' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Affine/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Affine/</guid><description>This dialect provides a powerful abstraction for affine operations and analyses.
Polyhedral Structures Dimensions and Symbols Restrictions on Dimensions and Symbols Affine Expressions Affine Maps Semi-affine maps Integer Sets Operations affine.apply (affine::AffineApplyOp) affine.delinearize_index (affine::AffineDelinearizeIndexOp) affine.for (affine::AffineForOp) affine.if (affine::AffineIfOp) affine.load (affine::AffineLoadOp) affine.max (affine::AffineMaxOp) affine.min (affine::AffineMinOp) affine.parallel (affine::AffineParallelOp) affine.prefetch (affine::AffinePrefetchOp) affine.store (affine::AffineStoreOp) affine.vector_load (affine::AffineVectorLoadOp) affine.vector_store (affine::AffineVectorStoreOp) affine.yield (affine::AffineYieldOp) affine.dma_start (mlir::AffineDmaStartOp) affine.dma_wait (mlir::AffineDmaWaitOp) Polyhedral Structures MLIR uses techniques from polyhedral compilation to make dependence analysis and loop transformations efficient and reliable.</description></item><item><title>'amdgpu' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/AMDGPU/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/AMDGPU/</guid><description>The AMDGPU dialect provides wrappers around AMD-specific functionality and LLVM intrinsics. These wrappers should be used in conjunction with more generic dialects, such as gpu and vector, when generating LLVM IR that will eventually be executed on AMD hardware.
Operations amdgpu.ext_packed_fp8 (amdgpu::ExtPackedFp8Op) amdgpu.lds_barrier (amdgpu::LDSBarrierOp) amdgpu.mfma (amdgpu::MFMAOp) amdgpu.packed_stoch_round_fp8 (amdgpu::PackedStochRoundFp8Op) amdgpu.packed_trunc_2xfp8 (amdgpu::PackedTrunc2xFp8Op) amdgpu.raw_buffer_atomic_cmpswap (amdgpu::RawBufferAtomicCmpswapOp) amdgpu.raw_buffer_atomic_fadd (amdgpu::RawBufferAtomicFaddOp) amdgpu.raw_buffer_atomic_fmax (amdgpu::RawBufferAtomicFmaxOp) amdgpu.raw_buffer_atomic_smax (amdgpu::RawBufferAtomicSmaxOp) amdgpu.raw_buffer_atomic_umin (amdgpu::RawBufferAtomicUminOp) amdgpu.raw_buffer_load (amdgpu::RawBufferLoadOp) amdgpu.raw_buffer_store (amdgpu::RawBufferStoreOp) amdgpu.wmma (amdgpu::WMMAOp) Attributes MFMAPermBAttr Operations source</description></item><item><title>'amx' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/AMX/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/AMX/</guid><description>The Intel Advanced Matrix Extensions (AMX) provide a tile matrix multiply unit (TMUL), a tile control register (TILECFG), and eight tile registers TMM0 through TMM7 (TILEDATA).
This AMX dialect provides a bridge between MLIR concepts such as vectors and memrefs and the lower level LLVM IR support of AMX. The dialect is split into user-facing AMX ops (AMX_Op) and backend-facing intrinsic ops (AMX_IntrOp).
Note that since configuration changes (implicit at dialect level) are costly, it is highly recommended to use the AMX dialect on same-shaped vectors, at least within a single method.</description></item><item><title>'arith' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ArithOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ArithOps/</guid><description>The arith dialect is intended to hold basic integer and floating point mathematical operations. This includes unary, binary, and ternary arithmetic ops, bitwise and shift ops, cast ops, and compare ops. Operations in this dialect also accept vectors and tensors of integers or floats. The dialect assumes integers are represented by bitvectors with a two&amp;rsquo;s complement representation. Unless otherwise stated, the operations within this dialect propagate poison values, i.e., if any of its inputs are poison, then the output is poison.</description></item><item><title>'arm_neon' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ArmNeon/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ArmNeon/</guid><description>Operations arm_neon.2d.sdot (arm_neon::Sdot2dOp) arm_neon.intr.sdot (arm_neon::SdotOp) arm_neon.intr.smull (arm_neon::SMullOp) Operations source
arm_neon.2d.sdot (arm_neon::Sdot2dOp) Sdot op
Syntax:
operation ::= `arm_neon.2d.sdot` $a `,` $b `,` $c attr-dict `:` type($b) `,` type($c) `to` type($res) The two input vectors b and c have a 2D shape, consisting of either 2 or 4 rows, each row having length 4. This operation computes the pair-wise dot-products of the rows of b and c and accumulates them with the corresponding entry of a:</description></item><item><title>'arm_sve' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ArmSVE/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ArmSVE/</guid><description>Basic dialect to target Arm SVE architectures This dialect contains the definitions necessary to target specific Arm SVE scalable vector operations.
Operations arm_sve.convert_from_svbool (arm_sve::ConvertFromSvboolOp) arm_sve.convert_to_svbool (arm_sve::ConvertToSvboolOp) arm_sve.intr.add (arm_sve::ScalableMaskedAddIIntrOp) arm_sve.intr.convert.from.svbool (arm_sve::ConvertFromSvboolIntrOp) arm_sve.intr.convert.to.svbool (arm_sve::ConvertToSvboolIntrOp) arm_sve.intr.fadd (arm_sve::ScalableMaskedAddFIntrOp) arm_sve.intr.fdiv (arm_sve::ScalableMaskedDivFIntrOp) arm_sve.intr.fmul (arm_sve::ScalableMaskedMulFIntrOp) arm_sve.intr.fsub (arm_sve::ScalableMaskedSubFIntrOp) arm_sve.intr.mul (arm_sve::ScalableMaskedMulIIntrOp) arm_sve.intr.sdiv (arm_sve::ScalableMaskedSDivIIntrOp) arm_sve.intr.sdot (arm_sve::SdotIntrOp) arm_sve.intr.smmla (arm_sve::SmmlaIntrOp) arm_sve.intr.sub (arm_sve::ScalableMaskedSubIIntrOp) arm_sve.intr.udiv (arm_sve::ScalableMaskedUDivIIntrOp) arm_sve.intr.udot (arm_sve::UdotIntrOp) arm_sve.intr.ummla (arm_sve::UmmlaIntrOp) arm_sve.masked.addf (arm_sve::ScalableMaskedAddFOp) arm_sve.masked.addi (arm_sve::ScalableMaskedAddIOp) arm_sve.masked.divf (arm_sve::ScalableMaskedDivFOp) arm_sve.masked.divi_signed (arm_sve::ScalableMaskedSDivIOp) arm_sve.masked.divi_unsigned (arm_sve::ScalableMaskedUDivIOp) arm_sve.masked.mulf (arm_sve::ScalableMaskedMulFOp) arm_sve.masked.muli (arm_sve::ScalableMaskedMulIOp) arm_sve.</description></item><item><title>'ArmSME' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ArmSME/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ArmSME/</guid><description>Basic dialect to target Arm SME.
This dialect defines custom and LLVM IR intrinsic operations that are used to target Arm Scalable Matrix Extension. Through the available conversion and ArmSME passes you can, for example, lower a linalg.matmul opereation to Arm SME FMOPA (floating-point outer product) operations. See one of the in-tree end-to-end integration tests for reference:
Linalg/CPU/ArmSME/matmul.mlir Vector/CPU/ArmSME/test-outerproduct-f64.mlir These tests are run &amp;ldquo;post-commit&amp;rdquo; by the clang-aarch64-sve-vla LLVM BuildBot worker.</description></item><item><title>'async' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/AsyncDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/AsyncDialect/</guid><description>Types and operations for async dialect This dialect contains operations for modeling asynchronous execution.
Operations async.add_to_group (async::AddToGroupOp) async.await (async::AwaitOp) async.await_all (async::AwaitAllOp) async.call (async::CallOp) async.coro.begin (async::CoroBeginOp) async.coro.end (async::CoroEndOp) async.coro.free (async::CoroFreeOp) async.coro.id (async::CoroIdOp) async.coro.save (async::CoroSaveOp) async.coro.suspend (async::CoroSuspendOp) async.create_group (async::CreateGroupOp) async.execute (async::ExecuteOp) async.func (async::FuncOp) async.return (async::ReturnOp) async.runtime.add_ref (async::RuntimeAddRefOp) async.runtime.add_to_group (async::RuntimeAddToGroupOp) async.runtime.await (async::RuntimeAwaitOp) async.runtime.await_and_resume (async::RuntimeAwaitAndResumeOp) async.runtime.create (async::RuntimeCreateOp) async.runtime.create_group (async::RuntimeCreateGroupOp) async.runtime.drop_ref (async::RuntimeDropRefOp) async.runtime.is_error (async::RuntimeIsErrorOp) async.runtime.load (async::RuntimeLoadOp) async.runtime.num_worker_threads (async::RuntimeNumWorkerThreadsOp) async.runtime.resume (async::RuntimeResumeOp) async.runtime.set_available (async::RuntimeSetAvailableOp) async.runtime.set_error (async::RuntimeSetErrorOp) async.</description></item><item><title>'bufferization' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/BufferizationOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/BufferizationOps/</guid><description>Bufferization in MLIR is the process of converting the tensor type to the memref type. Simply put, bufferization is the process of converting computations on the mathematical tensor construct to computations on physical memory buffers. The bufferization dialect contains operations/interfaces specific to the bufferization passes.
An overview of the bufferization infrastructure and important conceptual details related to using the MLIR dialect conversion infrastructure can be found in bufferization and buffer deallocation.</description></item><item><title>'cf' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ControlFlowDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ControlFlowDialect/</guid><description>This dialect contains low-level, i.e. non-region based, control flow constructs. These constructs generally represent control flow directly on SSA blocks of a control flow graph.
Operations cf.assert (cf::AssertOp) cf.br (cf::BranchOp) cf.cond_br (cf::CondBranchOp) cf.switch (cf::SwitchOp) Operations source
cf.assert (cf::AssertOp) Assert operation with message attribute
Syntax:
operation ::= `cf.assert` $arg `,` $msg attr-dict Assert operation at runtime with single boolean operand and an error message attribute. If the argument is true this operation has no effect.</description></item><item><title>'complex' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ComplexOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ComplexOps/</guid><description>The complex dialect is intended to hold complex numbers creation and arithmetic ops.
Operations complex.abs (complex::AbsOp) complex.add (complex::AddOp) complex.angle (complex::AngleOp) complex.atan2 (complex::Atan2Op) complex.bitcast (complex::BitcastOp) complex.conj (complex::ConjOp) complex.constant (complex::ConstantOp) complex.cos (complex::CosOp) complex.create (complex::CreateOp) complex.div (complex::DivOp) complex.eq (complex::EqualOp) complex.exp (complex::ExpOp) complex.expm1 (complex::Expm1Op) complex.im (complex::ImOp) complex.log (complex::LogOp) complex.log1p (complex::Log1pOp) complex.mul (complex::MulOp) complex.neg (complex::NegOp) complex.neq (complex::NotEqualOp) complex.pow (complex::PowOp) complex.re (complex::ReOp) complex.rsqrt (complex::RsqrtOp) complex.sign (complex::SignOp) complex.sin (complex::SinOp) complex.sqrt (complex::SqrtOp) complex.sub (complex::SubOp) complex.tan (complex::TanOp) complex.tanh (complex::TanhOp) Operations source</description></item><item><title>'dlti' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/DLTIDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/DLTIDialect/</guid><description> The Data Layout and Target Information (DLTI) dialect is intended to hold attributes and other components pertaining to descriptions of in-memory data layout and compilation targets.
Attribute constraints Target data layout entry Target data layout specification Attribute constraints Target data layout entry Target data layout specification</description></item><item><title>'emitc' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/EmitC/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/EmitC/</guid><description>Dialect to generate C/C++ from MLIR. The EmitC dialect allows to convert operations from other MLIR dialects to EmitC ops. Those can be translated to C/C++ via the Cpp emitter.
The following convention is followed:
If template arguments are passed to an emitc.call_opaque operation, C++ is generated. If tensors are used, C++ is generated. If multiple return values are used within in a functions or an emitc.call_opaque operation, C++11 is required.</description></item><item><title>'func' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Func/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Func/</guid><description>This dialect provides documentation for operations within the Func dialect.
This dialect contains operations surrounding high order function abstractions, such as calls.
Please post an RFC on the forum before adding or changing any operation in this dialect.
Operations func.call_indirect (func::CallIndirectOp) func.call (func::CallOp) func.constant (func::ConstantOp) func.func (func::FuncOp) func.return (func::ReturnOp) Operations source
func.call_indirect (func::CallIndirectOp) Indirect call operation
Syntax:
operation ::= `func.call_indirect` $callee `(` $callee_operands `)` attr-dict `:` type($callee) The func.call_indirect operation represents an indirect call to a value of function type.</description></item><item><title>'gpu' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/GPU/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/GPU/</guid><description>Note: this dialect is more likely to change than others in the near future; use with caution.
This dialect provides middle-level abstractions for launching GPU kernels following a programming model similar to that of CUDA or OpenCL. It provides abstractions for kernel invocations (and may eventually provide those for device management) that are not present at the lower level (e.g., as LLVM IR intrinsics for GPUs). Its goal is to abstract away device- and driver-specific manipulations to launch a GPU kernel and provide a simple path towards GPU execution from MLIR.</description></item><item><title>'index' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/IndexOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/IndexOps/</guid><description>The Index dialect The Index dialect contains operations for manipulating values of the builtin index type. The index type models target-specific values of pointer width, like intptr_t. Index values are typically used as loop bounds, array subscripts, tensor dimensions, etc.
The operations in this dialect operate exclusively on scalar index types. The dialect and its operations treat the index type as signless and contains signed and unsigned versions of certain operations where the distinction is meaningful.</description></item><item><title>'irdl' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/IRDL/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/IRDL/</guid><description>IR Definition Language Dialect IRDL is an SSA-based declarative representation of dynamic dialects. It allows the definition of dialects, operations, attributes, and types, with a declarative description of their verifiers. IRDL code is meant to be generated and not written by hand. As such, the design focuses on ease of generation/analysis instead of ease of writing/reading.
Users can define a new dialect with irdl.dialect, operations with irdl.operation, types with irdl.</description></item><item><title>'llvm' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/LLVM/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/LLVM/</guid><description>This dialect maps LLVM IR into MLIR by defining the corresponding operations and types. LLVM IR metadata is usually represented as MLIR attributes, which offer additional structure verification.
We use &amp;ldquo;LLVM IR&amp;rdquo; to designate the intermediate representation of LLVM and &amp;ldquo;LLVM dialect&amp;rdquo; or &amp;ldquo;LLVM IR dialect&amp;rdquo; to refer to this MLIR dialect.
Unless explicitly stated otherwise, the semantics of the LLVM dialect operations must correspond to the semantics of LLVM IR instructions and any divergence is considered a bug.</description></item><item><title>'math' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/MathOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MathOps/</guid><description>The math dialect is intended to hold mathematical operations on integer and floating types beyond simple arithmetics. Each operation works on scalar, vector or tensor type. On vector and tensor type operations apply elementwise unless explicitly specified otherwise. As an example, the floating point absolute value can be expressed as:
// Scalar absolute value. %a = math.absf %b : f64 // Vector elementwise absolute value. %f = math.absf %g : vector&amp;lt;4xf32&amp;gt; // Tensor elementwise absolute value.</description></item><item><title>'memref' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/MemRef/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MemRef/</guid><description>This dialect provides documentation for operations within the MemRef dialect.
Please post an RFC on the forum before adding or changing any operation in this dialect.
Operations memref.assume_alignment (memref::AssumeAlignmentOp) memref.atomic_rmw (memref::AtomicRMWOp) memref.atomic_yield (memref::AtomicYieldOp) memref.copy (memref::CopyOp) memref.generic_atomic_rmw (memref::GenericAtomicRMWOp) memref.load (memref::LoadOp) memref.alloc (memref::AllocOp) memref.alloca (memref::AllocaOp) memref.alloca_scope (memref::AllocaScopeOp) memref.alloca_scope.return (memref::AllocaScopeReturnOp) memref.cast (memref::CastOp) memref.collapse_shape (memref::CollapseShapeOp) memref.dealloc (memref::DeallocOp) memref.dim (memref::DimOp) memref.dma_start (memref::DmaStartOp) memref.dma_wait (memref::DmaWaitOp) memref.expand_shape (memref::ExpandShapeOp) memref.extract_aligned_pointer_as_index (memref::ExtractAlignedPointerAsIndexOp) memref.extract_strided_metadata (memref::ExtractStridedMetadataOp) memref.get_global (memref::GetGlobalOp) memref.global (memref::GlobalOp) memref.memory_space_cast (memref::MemorySpaceCastOp) memref.</description></item><item><title>'mesh' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Mesh/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Mesh/</guid><description>The mesh dialect contains a set of attributes, operations and interfaces that are useful for representing sharding and communication on a device mesh cluster.
Collective Communication Operations Device groups In-group Device Operations Operations mesh.all_gather (mesh::AllGatherOp) mesh.all_reduce (mesh::AllReduceOp) mesh.all_to_all (mesh::AllToAllOp) mesh.broadcast (mesh::BroadcastOp) mesh.cluster (mesh::ClusterOp) mesh.gather (mesh::GatherOp) mesh.recv (mesh::RecvOp) mesh.reduce (mesh::ReduceOp) mesh.reduce_scatter (mesh::ReduceScatterOp) mesh.scatter (mesh::ScatterOp) mesh.send (mesh::SendOp) mesh.shard (mesh::ShardOp) mesh.shift (mesh::ShiftOp) Attributes MeshShardingAttr PartialAttr Attributes Collective Communication Operations There are a number of operations in the Mesh dialect to facilitate communication between devices in a mesh.</description></item><item><title>'ml_program' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/MLProgramOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MLProgramOps/</guid><description>The MLProgram dialect contains structural operations and types for defining a compiled Machine-Learning program, as created from common ML frameworks, such as TensorFlow, PyTorch, JAX, etc. It does not itself define computation ops common to such frameworks but establishes a common programming model for establishing modules, functions, globals and memory model components appropriate for such an abstract level of detail.
This dialect is under active development, and while stability is an eventual goal, it is not guaranteed at this juncture.</description></item><item><title>'nvgpu' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/NVGPU/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/NVGPU/</guid><description>The NVGPU dialect provides a bridge between higher-level target-agnostic dialects (GPU and Vector) and the lower-level target-specific dialect (LLVM IR based NVVM dialect) for NVIDIA GPUs. This allow representing PTX specific operations while using MLIR high level dialects such as Memref and Vector for memory and target-specific register operands, respectively.
Operations nvgpu.device_async_copy (nvgpu::DeviceAsyncCopyOp) nvgpu.device_async_create_group (nvgpu::DeviceAsyncCreateGroupOp) nvgpu.device_async_wait (nvgpu::DeviceAsyncWaitOp) nvgpu.ldmatrix (nvgpu::LdMatrixOp) nvgpu.mbarrier.arrive (nvgpu::MBarrierArriveOp) nvgpu.mbarrier.arrive.expect_tx (nvgpu::MBarrierArriveExpectTxOp) nvgpu.mbarrier.arrive.nocomplete (nvgpu::MBarrierArriveNoCompleteOp) nvgpu.mbarrier.create (nvgpu::MBarrierCreateOp) nvgpu.mbarrier.init (nvgpu::MBarrierInitOp) nvgpu.</description></item><item><title>'nvvm' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/NVVMDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/NVVMDialect/</guid><description>Operations nvvm.bar.warp.sync (NVVM::SyncWarpOp) nvvm.barrier0 (NVVM::Barrier0Op) nvvm.cluster.arrive (NVVM::ClusterArriveOp) nvvm.cluster.arrive.relaxed (NVVM::ClusterArriveRelaxedOp) nvvm.cluster.wait (NVVM::ClusterWaitOp) nvvm.cp.async.bulk.commit.group (NVVM::CpAsyncBulkCommitGroupOp) nvvm.cp.async.bulk.tensor.global.shared.cta (NVVM::CpAsyncBulkTensorSharedCTAToGlobalOp) nvvm.cp.async.bulk.tensor.shared.cluster.global (NVVM::CpAsyncBulkTensorGlobalToSharedClusterOp) nvvm.cp.async.commit.group (NVVM::CpAsyncCommitGroupOp) nvvm.cp.async.mbarrier.arrive (NVVM::CpAsyncMBarrierArriveOp) nvvm.cp.async.mbarrier.arrive.shared (NVVM::CpAsyncMBarrierArriveSharedOp) nvvm.cp.async.shared.global (NVVM::CpAsyncOp) nvvm.cp.async.wait.group (NVVM::CpAsyncWaitGroupOp) nvvm.elect.sync (NVVM::ElectSyncOp) nvvm.fence.mbarrier.init (NVVM::FenceMbarrierInitOp) nvvm.fence.proxy (NVVM::FenceProxyOp) nvvm.fence.sc.cluster (NVVM::FenceScClusterOp) nvvm.ldmatrix (NVVM::LdMatrixOp) nvvm.mbarrier.arrive (NVVM::MBarrierArriveOp) nvvm.mbarrier.arrive.expect_tx (NVVM::MBarrierArriveExpectTxOp) nvvm.mbarrier.arrive.expect_tx.shared (NVVM::MBarrierArriveExpectTxSharedOp) nvvm.mbarrier.arrive.nocomplete (NVVM::MBarrierArriveNocompleteOp) nvvm.mbarrier.arrive.nocomplete.shared (NVVM::MBarrierArriveNocompleteSharedOp) nvvm.mbarrier.arrive.shared (NVVM::MBarrierArriveSharedOp) nvvm.mbarrier.init (NVVM::MBarrierInitOp) nvvm.mbarrier.init.shared (NVVM::MBarrierInitSharedOp) nvvm.mbarrier.inval (NVVM::MBarrierInvalOp) nvvm.mbarrier.inval.shared (NVVM::MBarrierInvalSharedOp) nvvm.mbarrier.test.wait (NVVM::MBarrierTestWaitOp) nvvm.mbarrier.test.wait.shared (NVVM::MBarrierTestWaitSharedOp) nvvm.mbarrier.try_wait.parity (NVVM::MBarrierTryWaitParityOp) nvvm.mbarrier.try_wait.parity.shared (NVVM::MBarrierTryWaitParitySharedOp) nvvm.mma.sync (NVVM::MmaOp) nvvm.prefetch.tensormap (NVVM::PrefetchTensorMapOp) nvvm.</description></item><item><title>'omp' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/OpenMPDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/OpenMPDialect/</guid><description>Operations omp.atomic.capture (omp::AtomicCaptureOp) omp.atomic.read (omp::AtomicReadOp) omp.atomic.update (omp::AtomicUpdateOp) omp.atomic.write (omp::AtomicWriteOp) omp.barrier (omp::BarrierOp) omp.bounds (omp::DataBoundsOp) omp.cancel (omp::CancelOp) omp.cancellationpoint (omp::CancellationPointOp) omp.critical (omp::CriticalOp) omp.critical.declare (omp::CriticalDeclareOp) omp.flush (omp::FlushOp) omp.map_info (omp::MapInfoOp) omp.master (omp::MasterOp) omp.ordered (omp::OrderedOp) omp.ordered_region (omp::OrderedRegionOp) omp.parallel (omp::ParallelOp) omp.reduction (omp::ReductionOp) omp.reduction.declare (omp::ReductionDeclareOp) omp.section (omp::SectionOp) omp.sections (omp::SectionsOp) omp.simdloop (omp::SimdLoopOp) omp.single (omp::SingleOp) omp.target (omp::TargetOp) omp.target_data (omp::DataOp) omp.target_enter_data (omp::EnterDataOp) omp.target_exit_data (omp::ExitDataOp) omp.task (omp::TaskOp) omp.taskgroup (omp::TaskGroupOp) omp.taskloop (omp::TaskLoopOp) omp.taskwait (omp::TaskwaitOp) omp.taskyield (omp::TaskyieldOp) omp.teams (omp::TeamsOp) omp.terminator (omp::TerminatorOp) omp.threadprivate (omp::ThreadprivateOp) omp.</description></item><item><title>'pdl_interp' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/PDLInterpOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/PDLInterpOps/</guid><description>Interpreted pattern execution dialect The PDL Interpreter dialect provides a lower level abstraction compared to the PDL dialect, and is targeted towards low level optimization and interpreter code generation. The dialect operations encapsulates low-level pattern match and rewrite &amp;ldquo;primitives&amp;rdquo;, such as navigating the IR (Operation::getOperand), creating new operations (OpBuilder::create), etc. Many of the operations within this dialect also fuse branching control flow with some form of a predicate comparison operation.</description></item><item><title>'pdl' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/PDLOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/PDLOps/</guid><description>High level pattern definition dialect PDL presents a high level abstraction for the rewrite pattern infrastructure available in MLIR. This abstraction allows for representing patterns transforming MLIR, as MLIR. This allows for applying all of the benefits that the general MLIR infrastructure provides, to the infrastructure itself. This means that pattern matching can be more easily verified for correctness, targeted by frontends, and optimized.
PDL abstracts over various different aspects of patterns and core MLIR data structures.</description></item><item><title>'quant' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/QuantDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/QuantDialect/</guid><description>Operations quant.dcast (quant::DequantizeCastOp) quant.qcast (quant::QuantizeCastOp) quant.scast (quant::StorageCastOp) Type constraints UniformQuantizedType Operations source
quant.dcast (quant::DequantizeCastOp) Convert back from a quantized to quantizable (expressed) type operation
A DequantizeCast op dcast represents the inverse of a qcast, converting back from a quantized to quantizable (expressed) type.
Like qcasts, a dcast is allowed to have both its operand and result as non quantized types. This facilitates transformations and marks edges where the computation must be carried out in the expressed type.</description></item><item><title>'rocdl' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ROCDLDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ROCDLDialect/</guid><description>Operations rocdl.barrier (ROCDL::BarrierOp) rocdl.buffer.load (ROCDL::MubufLoadOp) rocdl.buffer.store (ROCDL::MubufStoreOp) rocdl.cvt.f32.bf8 (ROCDL::CvtF32Bf8Op) rocdl.cvt.f32.fp8 (ROCDL::CvtF32Fp8Op) rocdl.cvt.pk.bf8.f32 (ROCDL::CvtPkBf8F32Op) rocdl.cvt.pk.fp8.f32 (ROCDL::CvtPkFp8F32Op) rocdl.cvt.sr.bf8.f32 (ROCDL::CvtSrBf8F32Op) rocdl.cvt.sr.fp8.f32 (ROCDL::CvtSrFp8F32Op) rocdl.ds_bpermute (ROCDL::DsBpermuteOp) rocdl.ds_swizzle (ROCDL::DsSwizzleOp) rocdl.grid.dim.x (ROCDL::GridDimXOp) rocdl.grid.dim.y (ROCDL::GridDimYOp) rocdl.grid.dim.z (ROCDL::GridDimZOp) rocdl.make.buffer.rsrc (ROCDL::MakeBufferRsrcOp) rocdl.mbcnt.hi (ROCDL::MbcntHiOp) rocdl.mbcnt.lo (ROCDL::MbcntLoOp) rocdl.mfma.f32.16x16x16bf16.1k (ROCDL::mfma_f32_16x16x16bf16_1k) rocdl.mfma.f32.16x16x16f16 (ROCDL::mfma_f32_16x16x16f16) rocdl.mfma.f32.16x16x1f32 (ROCDL::mfma_f32_16x16x1f32) rocdl.mfma.f32.16x16x2bf16 (ROCDL::mfma_f32_16x16x2bf16) rocdl.mfma.f32.16x16x32.bf8.bf8 (ROCDL::mfma_f32_16x16x32_bf8_bf8) rocdl.mfma.f32.16x16x32.bf8.fp8 (ROCDL::mfma_f32_16x16x32_bf8_fp8) rocdl.mfma.f32.16x16x32.fp8.bf8 (ROCDL::mfma_f32_16x16x32_fp8_bf8) rocdl.mfma.f32.16x16x32.fp8.fp8 (ROCDL::mfma_f32_16x16x32_fp8_fp8) rocdl.mfma.f32.16x16x4bf16.1k (ROCDL::mfma_f32_16x16x4bf16_1k) rocdl.mfma.f32.16x16x4f16 (ROCDL::mfma_f32_16x16x4f16) rocdl.mfma.f32.16x16x4f32 (ROCDL::mfma_f32_16x16x4f32) rocdl.mfma.f32.16x16x8.xf32 (ROCDL::mfma_f32_16x16x8_xf32) rocdl.mfma.f32.16x16x8bf16 (ROCDL::mfma_f32_16x16x8bf16) rocdl.mfma.f32.32x32x16.bf8.bf8 (ROCDL::mfma_f32_32x32x16_bf8_bf8) rocdl.mfma.f32.32x32x16.bf8.fp8 (ROCDL::mfma_f32_32x32x16_bf8_fp8) rocdl.mfma.f32.32x32x16.fp8.bf8 (ROCDL::mfma_f32_32x32x16_fp8_bf8) rocdl.mfma.f32.32x32x16.fp8.fp8 (ROCDL::mfma_f32_32x32x16_fp8_fp8) rocdl.</description></item><item><title>'scf' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/SCFDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SCFDialect/</guid><description>The scf (structured control flow) dialect contains operations that represent control flow constructs such as if and for. Being structured means that the control flow has a structure unlike, for example, gotos or asserts. Unstructured control flow operations are located in the cf (control flow) dialect.
Originally, this dialect was developed as a common lowering stage for the affine and linalg dialects. Both convert to SCF loops instead of targeting branch-based CFGs directly.</description></item><item><title>'shape' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ShapeDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ShapeDialect/</guid><description>Description of operations &amp;amp; types within the Shape dialect as well as their usage.
Types and operations for shape dialect This dialect contains operations for shape inference.
Note: Unless explicitly stated, all functions that return a shape and take shapes as input, return the invalid shape if one of its operands is an invalid shape. This avoids flagging multiple errors for one verification failure. The dialect itself does not specify how errors should be combined (there are multiple different options, from always choosing first operand, concatting etc.</description></item><item><title>'sparse_tensor' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/SparseTensorOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SparseTensorOps/</guid><description>The SparseTensor dialect supports all the attributes, types, operations, and passes that are required to make sparse tensor types first class citizens within the MLIR compiler infrastructure. The dialect forms a bridge between high-level operations on sparse tensors types and lower-level operations on the actual sparse storage schemes consisting of positions, coordinates, and values. Lower-level support may consist of fully generated code or may be provided by means of a small sparse runtime support library.</description></item><item><title>'tensor' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/TensorOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/TensorOps/</guid><description>The tensor dialect is intended to hold core tensor creation and manipulation ops, which are not strongly associated with any particular other dialect or domain abstraction. The aim for ops in this dialect is that they make sense for any tensor element type. When this is not the case, the op is left to live in other dialects. Examples of element types that could be supported by the tensor dialect include:</description></item><item><title>'ub' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/UBOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/UBOps/</guid><description>Operations ub.poison (ub::PoisonOp) Attributes PoisonAttr Operations source
ub.poison (ub::PoisonOp) Poisoned constant operation.
Syntax:
operation ::= `ub.poison` attr-dict (`&amp;lt;` $value^ `&amp;gt;`)? `:` type($result) The poison operation materializes a compile-time poisoned constant value to indicate deferred undefined behavior. value attribute is needed to indicate an optional additional poison semantics (e.g. partially poisoned vectors), default value indicates results is fully poisoned.
Syntax:
poison-op ::= `poison` (`&amp;lt;` value `&amp;gt;`)? `:` type Examples:
// Short form %0 = ub.</description></item><item><title>'vector' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Vector/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Vector/</guid><description>Positioning in the Codegen Infrastructure Components of a Generic Retargetable Vector-Level Dialect Short Description of the Existing Infrastructure LLVM level Hardware Vector Ops Virtual Vector Ops Virtual Vector Rewrite Patterns Virtual Vector to Hardware Vector Lowering Rationale Hardware as vector Machines of Minimum Granularity Transformations Problems Avoided The Big Out-Of-Scope Piece: Automatic Vectorization Bikeshed Naming Discussion 0D Vectors LLVM Lowering Tradeoffs Alternatives For Lowering an n-D Vector Type to LLVM Constraints Inherited from LLVM (see LangRef) Nested Aggregate Flattened 1-D Vector Type Discussion Relationship to LLVM matrix type proposal.</description></item><item><title>'x86vector' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/X86Vector/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/X86Vector/</guid><description>Operations x86vector.avx.intr.dot (x86vector::DotOp) x86vector.avx.intr.dp.ps.256 (x86vector::DotIntrOp) x86vector.avx.intr.rsqrt.ps.256 (x86vector::RsqrtIntrOp) x86vector.avx.rsqrt (x86vector::RsqrtOp) x86vector.avx512.intr.mask.compress (x86vector::MaskCompressIntrOp) x86vector.avx512.intr.mask.rndscale.pd.512 (x86vector::MaskRndScalePDIntrOp) x86vector.avx512.intr.mask.rndscale.ps.512 (x86vector::MaskRndScalePSIntrOp) x86vector.avx512.intr.mask.scalef.pd.512 (x86vector::MaskScaleFPDIntrOp) x86vector.avx512.intr.mask.scalef.ps.512 (x86vector::MaskScaleFPSIntrOp) x86vector.avx512.intr.vp2intersect.d.512 (x86vector::Vp2IntersectDIntrOp) x86vector.avx512.intr.vp2intersect.q.512 (x86vector::Vp2IntersectQIntrOp) x86vector.avx512.mask.compress (x86vector::MaskCompressOp) x86vector.avx512.mask.rndscale (x86vector::MaskRndScaleOp) x86vector.avx512.mask.scalef (x86vector::MaskScaleFOp) x86vector.avx512.vp2intersect (x86vector::Vp2IntersectOp) Operations source
x86vector.avx.intr.dot (x86vector::DotOp) Dot
Syntax:
operation ::= `x86vector.avx.intr.dot` $a `,` $b attr-dict `:` type($res) Computes the 4-way dot products of the lower and higher parts of the source vectors and broadcasts the two results to the lower and higher elements of the destination vector, respectively.</description></item><item><title>Builtin Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Builtin/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Builtin/</guid><description>The builtin dialect contains a core set of Attributes, Operations, and Types that have wide applicability across a very large number of domains and abstractions. Many of the components of this dialect are also instrumental in the implementation of the core IR. As such, this dialect is implicitly loaded in every MLIRContext, and available directly to all users of MLIR.
Given the far-reaching nature of this dialect and the fact that MLIR is extensible by design, any potential additions are heavily scrutinized.</description></item><item><title>OpInterface definitions</title><link>https://mlir.llvm.org/docs/Dialects/MatchOpInterfaces/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MatchOpInterfaces/</guid><description>ConversionPatternDescriptorOpInterface (ConversionPatternDescriptorOpInterface) This interface should be implemented by ops that select conversion patterns of a transform.apply_patterns op. It provides a method to populate a rewrite pattern set with conversion patterns.
Note: Non-conversion rewrite patterns should not be populated with ConversionPatternDescriptorOpInterface because it is not generally safe to use non-conversion rewrite patterns as part of a dialect conversion.
Methods: populatePatterns void populatePatterns(::mlir::TypeConverter &amp;amp;typeConverter, ::mlir::RewritePatternSet &amp;amp;patterns); Populate conversion patterns into the given pattern set with the given type converter.</description></item><item><title>SPIR-V Dialect</title><link>https://mlir.llvm.org/docs/Dialects/SPIR-V/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SPIR-V/</guid><description>This document describes the design of the SPIR-V dialect in MLIR. It lists various design choices we made for modeling different SPIR-V mechanisms, and their rationale.
This document also explains in a high-level manner how different components are organized and implemented in the code and gives steps to follow for extending them.
This document assumes familiarity with SPIR-V. SPIR-V is the Khronos Group’s binary intermediate language for representing graphics shaders and compute kernels.</description></item><item><title>Tensor Operator Set Architecture (TOSA) Dialect</title><link>https://mlir.llvm.org/docs/Dialects/TOSA/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/TOSA/</guid><description>Rationale TOSA and Tensor Level Expressiveness Complete Minimal Numerical Precision TOSA Operator Rationale COND_IF and WHILE_LOOP Using TOSA In A Compiler Quantization Parameters in Ops vs Tensors Operation definitions tosa.abs (mlir::tosa::AbsOp) tosa.add (mlir::tosa::AddOp) tosa.apply_scale (mlir::tosa::ApplyScaleOp) tosa.argmax (mlir::tosa::ArgMaxOp) tosa.arithmetic_right_shift (mlir::tosa::ArithmeticRightShiftOp) tosa.avg_pool2d (mlir::tosa::AvgPool2dOp) tosa.bitwise_and (mlir::tosa::BitwiseAndOp) tosa.bitwise_not (mlir::tosa::BitwiseNotOp) tosa.bitwise_or (mlir::tosa::BitwiseOrOp) tosa.bitwise_xor (mlir::tosa::BitwiseXorOp) tosa.cast (mlir::tosa::CastOp) tosa.ceil (mlir::tosa::CeilOp) tosa.clamp (mlir::tosa::ClampOp) tosa.clz (mlir::tosa::ClzOp) tosa.concat (mlir::tosa::ConcatOp) tosa.const (mlir::tosa::ConstOp) tosa.conv2d (mlir::tosa::Conv2DOp) tosa.conv3d (mlir::tosa::Conv3DOp) tosa.custom (mlir::tosa::CustomOp) tosa.depthwise_conv2d (mlir::tosa::DepthwiseConv2DOp) tosa.</description></item><item><title>Transform Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Transform/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Transform/</guid><description>Fine-grain transformation control dialect. See tutorial for more introductory information.
Overview Dialect Extension Mechanism Side Effects Execution Model Handle Invalidation Intended Use and Integrations Effects on the Infrastructure Type Definitions AffineMapParamType AnyOpType AnyParamType AnyValueType OperationType ParamType TypeParamType Core Operations transform.alternatives (transform::AlternativesOp) transform.annotate (transform::AnnotateOp) transform.apply_patterns.canonicalization (transform::ApplyCanonicalizationPatternsOp) transform.apply_cse (transform::ApplyCommonSubexpressionEliminationOp) transform.apply_conversion_patterns (transform::ApplyConversionPatternsOp) transform.apply_dce (transform::ApplyDeadCodeEliminationOp) transform.apply_licm (transform::ApplyLoopInvariantCodeMotionOp) transform.apply_patterns (transform::ApplyPatternsOp) transform.apply_registered_pass (transform::ApplyRegisteredPassOp) transform.apply_conversion_patterns.dialect_to_llvm (transform::ApplyToLLVMConversionPatternsOp) transform.cast (transform::CastOp) transform.foreach_match (transform::ForeachMatchOp) transform.foreach (transform::ForeachOp) transform.get_consumers_of_result (transform::GetConsumersOfResult) transform.get_defining_op (transform::GetDefiningOp) transform.get_parent_op (transform::GetParentOp) transform.</description></item></channel></rss>